{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2cdd21-3bfd-4ef7-a81a-da4b83c8f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import ipywidgets.widgets as widgets\n",
    "import random\n",
    "import colorsys\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e260ed75-7e05-4125-b074-6b8447886448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_boxes(box_xywh, scores, score_threshold, input_shape):\n",
    "    scores_max = tf.math.reduce_max(scores, axis=-1)\n",
    "\n",
    "    mask = scores_max >= score_threshold\n",
    "    class_boxes = tf.boolean_mask(box_xywh, mask)\n",
    "    pred_conf = tf.boolean_mask(scores, mask)\n",
    "    class_boxes = tf.reshape(class_boxes, [tf.shape(scores)[0], -1, tf.shape(class_boxes)[-1]])\n",
    "    pred_conf = tf.reshape(pred_conf, [tf.shape(scores)[0], -1, tf.shape(pred_conf)[-1]])\n",
    "\n",
    "    box_xy, box_wh = tf.split(class_boxes, (2, 2), axis=-1)\n",
    "\n",
    "    input_shape = tf.cast(input_shape, dtype=tf.float32)\n",
    "\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "\n",
    "    box_mins = (box_yx - (box_hw / 2.)) / input_shape\n",
    "    box_maxes = (box_yx + (box_hw / 2.)) / input_shape\n",
    "    boxes = tf.concat([\n",
    "        box_mins[..., 0:1],  # y_min\n",
    "        box_mins[..., 1:2],  # x_min\n",
    "        box_maxes[..., 0:1],  # y_max\n",
    "        box_maxes[..., 1:2]  # x_max\n",
    "    ], axis=-1)\n",
    "\n",
    "    return (boxes, pred_conf)\n",
    "\n",
    "def draw_bbox(image, bboxes, classes, colours, show_label=True):\n",
    "    num_classes = len(classes)\n",
    "    image_h, image_w, _ = image.shape\n",
    "\n",
    "    out_boxes, out_scores, out_classes, num_boxes = bboxes\n",
    "    for i in range(num_boxes[0]):\n",
    "        class_ind = int(out_classes[0][i])\n",
    "        if class_ind < 0 or class_ind >= num_classes: continue\n",
    "        coor = out_boxes[0][i]\n",
    "        coor[0] = int(coor[0] * image_h)\n",
    "        coor[2] = int(coor[2] * image_h)\n",
    "        coor[1] = int(coor[1] * image_w)\n",
    "        coor[3] = int(coor[3] * image_w)\n",
    "\n",
    "        fontScale = 0.5\n",
    "        score = out_scores[0][i]\n",
    "        \n",
    "        bbox_color = colours[class_ind]\n",
    "        c1, c2 = (int(coor[1]), int(coor[0])), (int(coor[3]), int(coor[2]))\n",
    "        cv.rectangle(image, c1, c2, bbox_color, 1)\n",
    "\n",
    "        if show_label:\n",
    "            bbox_mess = '%s: %.2f' % (classes[class_ind], score)\n",
    "            cv.putText(image, bbox_mess, (c1[0], (c1[1] - 2)), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale, (0, 0, 0), 1, lineType=cv.LINE_AA)\n",
    "\n",
    "def setup_tflite(model_path, labels):\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    class_names = {}\n",
    "    with open(labels, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            class_names[ID] = name.strip('\\n')\n",
    "\n",
    "    hsv_tuples = [(1.0 * x / len(class_names), 1., 1.) for x in range(len(class_names))]\n",
    "    colours = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    label_colours = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colours))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(label_colours)\n",
    "    random.seed(None)\n",
    "\n",
    "    return interpreter, input_details, output_details, class_names, label_colours\n",
    "\n",
    "def detect_tflite(interpreter, input_details, output_details, img, class_names, label_colours, int8=False, score_thresh = 0.5, iou_thresh = 0.4, input_size=416):\n",
    "    original_image = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    image_data = cv.resize(original_image, (input_size, input_size))\n",
    "    image_data = image_data / 255.\n",
    "\n",
    "    images_data = []\n",
    "    for i in range(1):\n",
    "        images_data.append(image_data)\n",
    "    images_data = np.asarray(images_data).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], images_data)\n",
    "    interpreter.invoke()\n",
    "    pred = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]\n",
    "\n",
    "    if (int8 == True):\n",
    "        NUM_CLASSES = len(class_names)\n",
    "        STRIDES = np.array([16, 32])\n",
    "        ANCHORS = (np.array([10,14, 23,27, 37,58, 81,82, 135,169, 344,319])).reshape(2, 3, 2)\n",
    "        XYSCALE = [1.05, 1.05]\n",
    "        bbox_tensors = []\n",
    "        prob_tensors = []\n",
    "        for i, fm in enumerate(pred):\n",
    "            if i == 0:\n",
    "                output_tensors = decode_tflite(pred[1], input_size // 16, NUM_CLASSES, STRIDES, ANCHORS, i, XYSCALE)\n",
    "            else:\n",
    "                output_tensors = decode_tflite(pred[0], input_size // 32, NUM_CLASSES, STRIDES, ANCHORS, i, XYSCALE)\n",
    "            bbox_tensors.append(output_tensors[0])\n",
    "            prob_tensors.append(output_tensors[1])\n",
    "\n",
    "        pred_bbox = tf.concat(bbox_tensors, axis=1)\n",
    "        pred_prob = tf.concat(prob_tensors, axis=1)\n",
    "        pred = (pred_bbox, pred_prob)\n",
    "\n",
    "    boxes, pred_conf = filter_boxes(pred[0], pred[1], score_thresh, input_shape=tf.constant([input_size, input_size]))\n",
    "    \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "        scores=tf.reshape(\n",
    "            pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "        max_output_size_per_class=50,\n",
    "        max_total_size=50,\n",
    "        iou_threshold=iou_thresh,\n",
    "        score_threshold=score_thresh\n",
    "    )\n",
    "\n",
    "    pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "    draw_bbox(original_image, pred_bbox, class_names, label_colours)\n",
    "    return original_image\n",
    "\n",
    "def decode_tflite(conv_output, output_size, NUM_CLASS, STRIDES, ANCHORS, i=0, XYSCALE=[1,1,1]):\n",
    "    conv_raw_dxdy_0, conv_raw_dwdh_0, conv_raw_score_0,\\\n",
    "    conv_raw_dxdy_1, conv_raw_dwdh_1, conv_raw_score_1,\\\n",
    "    conv_raw_dxdy_2, conv_raw_dwdh_2, conv_raw_score_2 = tf.split(conv_output, (2, 2, 1+NUM_CLASS, 2, 2, 1+NUM_CLASS,\n",
    "                                                                                2, 2, 1+NUM_CLASS), axis=-1)\n",
    "\n",
    "    conv_raw_score = [conv_raw_score_0, conv_raw_score_1, conv_raw_score_2]\n",
    "    for idx, score in enumerate(conv_raw_score):\n",
    "        score = tf.sigmoid(score)\n",
    "        score = score[:, :, :, 0:1] * score[:, :, :, 1:]\n",
    "        conv_raw_score[idx] = tf.reshape(score, (1, -1, NUM_CLASS))\n",
    "    pred_prob = tf.concat(conv_raw_score, axis=1)\n",
    "\n",
    "    conv_raw_dwdh = [conv_raw_dwdh_0, conv_raw_dwdh_1, conv_raw_dwdh_2]\n",
    "    for idx, dwdh in enumerate(conv_raw_dwdh):\n",
    "        dwdh = tf.exp(dwdh) * ANCHORS[i][idx]\n",
    "        conv_raw_dwdh[idx] = tf.reshape(dwdh, (1, -1, 2))\n",
    "    pred_wh = tf.concat(conv_raw_dwdh, axis=1)\n",
    "\n",
    "    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n",
    "    xy_grid = tf.stack(xy_grid, axis=-1)  # [gx, gy, 2]\n",
    "    xy_grid = tf.expand_dims(xy_grid, axis=0)\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    conv_raw_dxdy = [conv_raw_dxdy_0, conv_raw_dxdy_1, conv_raw_dxdy_2]\n",
    "    for idx, dxdy in enumerate(conv_raw_dxdy):\n",
    "        dxdy = ((tf.sigmoid(dxdy) * XYSCALE[i]) - 0.5 * (XYSCALE[i] - 1) + xy_grid) * \\\n",
    "              STRIDES[i]\n",
    "        conv_raw_dxdy[idx] = tf.reshape(dxdy, (1, -1, 2))\n",
    "    pred_xy = tf.concat(conv_raw_dxdy, axis=1)\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    t1=time.time()\n",
    "    return pred_xywh, pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc152fad-710b-4456-b37f-d137a92e872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera(capture, interpreter, input_details, output_details, class_names, label_colours):\n",
    "    start_time = time.time()\n",
    "    frame_count = 0\n",
    "    fps_total = 0\n",
    "    \n",
    "    global camera_stop\n",
    "    while capture.isOpened() and not camera_stop:\n",
    "        _, img = capture.read()\n",
    "\n",
    "        img = detect_tflite(interpreter, input_details, output_details, img, class_names, label_colours, True)\n",
    "        \n",
    "        cur_time = time.time()\n",
    "        elapsed = cur_time - start_time\n",
    "        start_time = cur_time\n",
    "        fps = 1/elapsed\n",
    "        frame_count += 1\n",
    "        fps_total += fps\n",
    "        avg_fps = fps_total/frame_count\n",
    "        fps_txt = \"FPS: {:.2f}, Avg FPS: {:.2f}\".format(fps, avg_fps)\n",
    "        cv.putText(img, fps_txt, (30, 430), cv.FONT_HERSHEY_COMPLEX_SMALL, 1, (0,0,255), 1)\n",
    "        img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "        image_widget.value = cv.imencode('.jpg', img)[1].tobytes()\n",
    "\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0522e75-36c9-479e-a46e-c00514edb3f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c171317d312646f3a2367effd94c1bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interpreter, input_details, output_details, class_names, label_colours = setup_tflite('yolov4-tiny-416int8test1.tflite', 'obj.names')\n",
    "\n",
    "capture = cv.VideoCapture(0)\n",
    "camera_stop = 0\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(image_widget)\n",
    "threading.Thread(target=camera, args=(capture,interpreter, input_details, output_details, class_names, label_colours,)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f088190-bfe4-4031-8632-7556a8cf46de",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_stop = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab39fcb-7994-490d-a7f7-53c56d696e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
